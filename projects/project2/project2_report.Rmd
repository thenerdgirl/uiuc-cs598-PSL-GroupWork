---
title: 'Project 2: Walmart Store Sales Forecasting'
author: "Naomi Bhagat - nbhagat3, Michael Miller - msmille3, Joe May - jemay3"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document: null
  html_document:
    df_print: paged
subtitle: 'CS598: Practical Statistical Learning'
urlcolor: cyan
header-includes:
- \setlength{\parindent}{2em}
- \setlength{\parskip}{0em}
---

# Assignment Data

Program: MCS-DS
Assignment post: [campuswire](https://campuswire.com/c/G06C55090/feed/339)


Team contributions:

| Person         | Contribution                                |
|----------------|---------------------------------------------|
| Naomi Bhagat   | Report |
| Michael Miller | Algorithm |
| Joe May        | Algotrithm, Report |

## Overview

Given historical sales data from 45 Walmart stores spread across different regions, our task was to predict the future weekly sales for every department in each store. The dataset is from https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting.

The measure we use for evaluation is the weighted mean absolute error (WMAE) between our predictions and the actual values of the weekly sales.

## Section 1: Technical Details

Our function `process_fold` is the meat of the prediction algortihm. We first read the training and test data in the given file directory parameter `file_dir`. 

We first clean the test data by introducing a new vairable `Wk` to numerically represent each week of the year, ranging from 1-52. We do the same thing with a new variable `Yr` to represent the year of the already existing `Date` in thetest dataset.

We then initialize an output matrix, a counter variable, and the a variable to keep track of the number of departments in the data. In order to speed up our processing speed, a variable called `dept_to_eval` is created to keep track of departments that exist in both the test data and the training data.

From here, we perform the same steps for each department stored in the `dept_to_eval` variable. Our first call is to a custom function called `spread_df`, which takes the parameters of the training data and the current department being evaluated. In the `spread_df` function, we start with a variable `X` which takes the training data and filters out any departments that are not the current department, as well as keeps the relevant data from the training data, including `Store`, `Date`, and `Weekly_Sales`. Finally, we use the `spread` function from the `tidyr` package to expand the training data to include top-level columns for `Store` and `Weekly_Sales`. After replacing all the `NA` values with 0 in `X`, we drop the `Date` row and take the transpose of `X`, and return a list consisting of X, stores, and dates.



## Section 2: Performance Metrics

The computer system this was run on was a Dell Inspiron 3501, 1.00 GHz with 8.00 GB of installed RAM for all 10 training/test splits. Below is a summary of the fold #, the WMAE for each fold, and the time it took to train the models:

| Fold | WMAE | Time (s) |
|------|------|----------|
| 1 | 1941.586 | 69.40 |
| 2 | 1363.507 | 67.85 |
| 3 | 1382.469 | 69.29 |
| 4 | 1527.293 | 80.14 |
| 5 | 2156.606 | 80.31 |
| 6 | 1634.892 | 78.32 |
| 7 | 1613.908 | 70.70 |
| 8 | 1355.016 | 68.13 |
| 9 | 1336.911 | 71.56 |
| 10 | 1334.010 | 73.67 |

The average WMAE over all folds is 1564.62.



